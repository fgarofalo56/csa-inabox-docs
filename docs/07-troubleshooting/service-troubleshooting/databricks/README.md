# Azure Databricks Troubleshooting Guide

> **[ğŸ  Home](../../../../README.md)** | **[ğŸ“– Documentation](../../../README.md)** | **[ğŸ”§ Troubleshooting](../../README.md)** | **ğŸ‘¤ Azure Databricks**

![Status](https://img.shields.io/badge/Status-Active-brightgreen) ![Service](https://img.shields.io/badge/Service-Databricks-orange)

Comprehensive troubleshooting guide for Azure Databricks including cluster issues, Spark performance, Delta Lake problems, and data quality concerns.

## Quick Navigation

| Issue Category | Description | Guide |
|:---------------|:------------|:------|
| ğŸš€ **Cluster Issues** | Startup failures, node provisioning | [Cluster Startup](cluster-startup.md) |
| ğŸ”¢ **Node Provisioning** | Node allocation, autoscaling | [Node Provisioning](node-provisioning.md) |
| ğŸ§  **Memory Issues** | OOM errors, memory pressure | [Memory Issues](memory-issues.md) |
| ğŸ“Š **Query Performance** | Slow queries, optimization | [Query Performance](query-performance.md) |
| ğŸ”„ **Shuffle Optimization** | Shuffle operations, spills | [Shuffle Optimization](shuffle-optimization.md) |
| ğŸ—ï¸ **Delta Lake Issues** | Delta table problems, transactions | [Delta Issues](delta-issues.md) |
| ğŸ“ **Schema Evolution** | Schema changes, compatibility | [Schema Evolution](schema-evolution.md) |
| ğŸŒ **Networking** | Connectivity, VNet integration | [Networking](networking.md) |
| âœ… **Data Quality** | Data validation, corruption | [Data Quality](data-quality.md) |

## Common Error Categories

### Cluster Errors

- Cluster start timeout
- Node termination
- Driver not responding
- Cloud provider limits reached

### Runtime Errors

- OutOfMemoryError
- StackOverflowError
- SparkException
- AnalysisException

### Data Errors

- File not found
- Schema mismatch
- Corrupt data files
- Concurrent modification

## Quick Diagnostics

### Check Cluster Health

```python
# Get cluster status
import requests

DATABRICKS_INSTANCE = "https://<workspace>.azuredatabricks.net"
TOKEN = dbutils.secrets.get(scope="<scope>", key="<key>")

def get_cluster_status(cluster_id):
    """Get current cluster status."""

    url = f"{DATABRICKS_INSTANCE}/api/2.0/clusters/get"
    headers = {"Authorization": f"Bearer {TOKEN}"}
    params = {"cluster_id": cluster_id}

    response = requests.get(url, headers=headers, params=params)
    cluster_info = response.json()

    print(f"Cluster: {cluster_info['cluster_name']}")
    print(f"State: {cluster_info['state']}")
    print(f"Spark Version: {cluster_info['spark_version']}")
    print(f"Nodes: {cluster_info.get('num_workers', 'N/A')}")

    return cluster_info
```

### Check Spark Configuration

```python
# Display current Spark configuration
spark.sparkContext.getConf().getAll()
```

## Support Escalation

Contact Databricks/Azure Support if:

- [ ] Persistent cluster start failures
- [ ] Unexplained job failures
- [ ] Data corruption issues
- [ ] Performance degradation without changes
- [ ] Billing/quota issues

## Related Resources

| Resource | Link |
|----------|------|
| **Databricks Documentation** | [docs.databricks.com](https://docs.databricks.com) |
| **Azure Databricks** | [Microsoft Docs](https://docs.microsoft.com/azure/databricks/) |
| **Spark Documentation** | [spark.apache.org](https://spark.apache.org/docs/latest/) |

---

**Last Updated:** 2025-12-10
**Version:** 1.0.0
