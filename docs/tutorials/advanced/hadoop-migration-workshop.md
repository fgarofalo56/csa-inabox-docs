# üîÑ Hadoop Migration Workshop

> __üè† [Home](../../../README.md)__ | __üìñ [Documentation](../../README.md)__ | __üéì [Tutorials](../README.md)__ | __üöÄ Advanced__ | __üîÑ Migration__

![Status](https://img.shields.io/badge/Status-Active-brightgreen)
![Level](https://img.shields.io/badge/Level-Advanced-red)
![Duration](https://img.shields.io/badge/Duration-120--150_minutes-blue)

__Migrate on-premises Hadoop workloads to Azure. Learn assessment, planning, and execution strategies.__

## üéØ Learning Objectives

- Assess on-premises Hadoop clusters
- Plan migration strategy
- Migrate data and workloads
- Optimize for Azure
- Validate and cutover

## üìã Prerequisites

- [ ] __On-premises Hadoop cluster__ or access
- [ ] __Azure subscription__ with adequate quota
- [ ] __HDInsight or Databricks experience__
- [ ] __Understanding of Hadoop architecture__

## üîç Step 1: Assessment

### __Inventory Collection__

```bash
# Collect cluster metrics
yarn node -list > cluster-nodes.txt
hdfs dfsadmin -report > hdfs-report.txt
yarn application -list -appStates ALL > applications.txt
hive -e "SHOW TABLES" > hive-tables.txt
```

### __Workload Analysis__

- Identify data sources and sizes
- Map job dependencies
- Document SLAs and performance requirements
- List security and compliance needs

## üìä Step 2: Migration Strategy

### __Lift and Shift vs Modernization**

__Lift and Shift (HDInsight)__
‚úÖ Fastest migration
‚úÖ Minimal code changes
‚ùå Limited modernization

__Modernize (Databricks/Synapse)__
‚úÖ Better performance
‚úÖ Modern features
‚ùå More effort

### __Migration Phases__

1. **Pilot** - 1-2 workloads
2. **Wave 1** - Non-critical workloads
3. **Wave 2** - Production workloads
4. **Decommission** - Turn off on-prem

## üöÄ Step 3: Data Migration

### __Use AzCopy or DistCp**

```bash
# DistCp from on-prem to Azure
hadoop distcp \
  hdfs://onprem-namenode:8020/data/* \
  wasb://container@storageaccount.blob.core.windows.net/data/

# AzCopy
azcopy copy \
  "hdfs://onprem-namenode:8020/data/*" \
  "https://storageaccount.blob.core.windows.net/container" \
  --recursive
```

## üîß Step 4: Workload Migration

### __Hive Scripts**

```sql
-- Migrate Hive tables
CREATE EXTERNAL TABLE sales_azure
STORED AS ORC
LOCATION 'wasb://data@storageaccount.blob.core.windows.net/sales/'
AS
SELECT * FROM sales_onprem;
```

### __MapReduce to Spark**

```python
# Modernize MapReduce to Spark
# Old MapReduce
# New Spark
df = spark.read.csv("wasb:///data/sales.csv")
result = df.groupBy("category").sum("amount")
```

## ‚úÖ Step 5: Validation

- Compare data counts
- Run test queries
- Benchmark performance
- Verify security

## üìö Resources

- [Azure Migration Guide](https://learn.microsoft.com/azure/architecture/data-guide/)
- [HDInsight Migration](https://learn.microsoft.com/azure/hdinsight/hdinsight-hadoop-on-premises-migration-best-practices-architecture)

---

*Last Updated: January 2025*
